@article{6-2-tunability,
author = {Probst, Philipp and Boulesteix, Anne-Laure and Bischl, Bernd},
title = {Tunability: Importance of Hyperparameters of Machine Learning Algorithms},
year = {2019},
issue_date = {January 2019},
publisher = {JMLR.org},
volume = {20},
number = {1},
issn = {1532-4435},
abstract = {Modern supervised machine learning algorithms involve hyperparameters that have to be set before running them. Options for setting hyperparameters are default values from the software package, manual configuration by the user or configuring them for optimal predictive performance by a tuning procedure. The goal of this paper is two-fold. Firstly, we formalize the problem of tuning from a statistical point of view, define databased defaults and suggest general measures quantifying the tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale benchmarking study based on 38 datasets from the OpenML platform and six common machine learning algorithms. We apply our measures to assess the tunability of their parameters. Our results yield default values for hyperparameters and enable users to decide whether it is worth conducting a possibly time consuming tuning strategy, to focus on the most important hyperparameters and to choose adequate hyperparameter spaces for tuning.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {1934â€“1965},
numpages = {32},
keywords = {machine learning, hyperparameters, tuning, classification, supervised learning, meta-learning}
}


